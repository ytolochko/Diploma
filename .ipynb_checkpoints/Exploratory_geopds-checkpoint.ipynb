{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conflict = pd.read_csv('Data\\\\conflict_data\\\\DRC_2.csv', header = 0, index_col = 0)\n",
    "\n",
    "aid = pd.read_csv('Data\\\\aid_data\\\\data\\\\level_1a.csv')\n",
    "aid = aid.dropna(subset=['latitude', 'longitude']) # drop those entries that don't have coordinates to them\n",
    "\n",
    "worker_deaths = pd.read_csv('Data\\\\security_incidents.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "provinces = gpd.read_file('Data\\\\gadm36_COD_shp/gadm36_COD_1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(conflict.longitude, conflict.latitude)]\n",
    "gconflict = gpd.GeoDataFrame(conflict, crs = {'init': 'epsg:4326'}, geometry = geometry)\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(aid.longitude, aid.latitude)]\n",
    "gaid = gpd.GeoDataFrame(aid, crs = {'init': 'epsg:4326'}, geometry = geometry)\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(worker_deaths.Longitude, worker_deaths.Latitude)]\n",
    "g_w_d = gpd.GeoDataFrame(worker_deaths, crs = {'init': 'epsg:4326'}, geometry = geometry) # g_w_d = gworker_deaths\n",
    "\n",
    "\n",
    "gconflict = gpd.sjoin(gconflict, provinces, how=\"inner\")\n",
    "gaid = gpd.sjoin(gaid, provinces, how=\"inner\")\n",
    "g_w_d = gpd.sjoin(g_w_d, provinces, how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the number of rows there column_name has more than one entry, separated by \"|\". We use this for donors and aid focus. \n",
    "def calc_multiples(df, column_name):\n",
    "    s = 0\n",
    "    l = []\n",
    "    for index, row in df.iterrows():\n",
    "        entries = row[column_name].split(\"|\")\n",
    "        if len(entries) > 1:\n",
    "            s += 1\n",
    "            l.append(index)\n",
    "    return s#, l\n",
    "# split those rows that have more than one entry in a certain column name.\n",
    "# We create a new row for each of the multiple entries (other entries being the same)\n",
    "# and delete the original multiple entry row. \n",
    "def split_rows(data, column_name):\n",
    "    df = copy.deepcopy(data)\n",
    "    temp = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        entries = row[column_name].split(\"|\")\n",
    "        if len(entries) > 1:\n",
    "            for entry in entries:\n",
    "                temp_row = row\n",
    "                temp_row[column_name] = entry\n",
    "                temp = temp.append(temp_row)\n",
    "            df.drop(index, inplace = True)\n",
    "            \n",
    "    return df.append(temp)\n",
    "\n",
    "# split the rows(projects) that have more than one donor per project\n",
    "gaid = split_rows(gaid, 'donors')\n",
    "gaid = split_rows(gaid, 'ad_sector_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('measures_indices'):\n",
    "    os.makedirs('measures_indices')\n",
    "    \n",
    "# how many projects there are per donor and their share in the total, save in a csv file  \n",
    "total = gaid['donors'].value_counts() # total N of projects per donor\n",
    "share = gaid['donors'].value_counts() / gaid.shape[0] # calculate share of the projects per donor in total N of projects\n",
    "pd.concat([total, share], axis = 1).to_csv('measures_indices\\\\N_projects_per_donor.csv')\n",
    "\n",
    "# what share of projects per donor have multiple focus sectors (e.g. General environmental protection|Transport and storage)\n",
    "multiple_focus_share = (gaid.groupby('donors').apply(calc_multiples, 'ad_sector_names') / gaid['donors'].value_counts())\n",
    "multiple_focus_share.to_csv('measures_indices\\\\project_multiple_sectors.csv')\n",
    "\n",
    "# share of each project focus in the total number of projects per donor. We use this to calculate variablity of project focus for a donor\n",
    "focus_share = (gaid.groupby(['donors', 'ad_sector_names']).size() / gaid.groupby(['donors']).size())\n",
    "focus_share.to_csv('measures_indices\\\\donor_sector_share.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Func calculates the coefficient of unalikeability (as defined by Kader 2007) of every sublcass of first_group variable by topic_name\n",
    "# E.g. unalikeability of project location for each aid donor -> calc_unalikeability(gaid, 'donors', 'ad_sector_names')\n",
    "\n",
    "def calc_unalikeability(data, first_group, topic_name):\n",
    "    \n",
    "    # prepare data: group by first_group and topic_name, and divide by the size of the respective group\n",
    "    # thus we obtain the share that each topic_name has in the respective first_group\n",
    "    \n",
    "    d = (data.groupby([first_group, topic_name]).size() / gaid.groupby([first_group]).size())\n",
    "    \n",
    "    # here we get the keys for the first level grouping. So, the unique values of first group column\n",
    "    keys = []\n",
    "    for i in d.index:\n",
    "        keys.append(i[0])\n",
    "    keys = set(keys)\n",
    "    \n",
    "    # here we calculate the actual coefficient\n",
    "    # for every value of first_group we calculate its coefficient:\n",
    "    # coefficient is defined as 1 - SUM_i(p_i^2), where p_i is the share of the ith subgroup in the total group. \n",
    "    \n",
    "    coefs = {}\n",
    "    for key in keys:\n",
    "        s = 0\n",
    "        for subgroup in d[key]:\n",
    "            s += subgroup ** 2\n",
    "        coef = 1 - s\n",
    "        coefs[key] = coef\n",
    "    return pd.Series(coefs)\n",
    "\n",
    "\n",
    "# calculates the variablity of topic_name (e.g. total commitments of money) for every member of first_group\n",
    "def calc_var(data, first_group, topic_name):\n",
    "    d = data.groupby(first_group)\n",
    "    \n",
    "    def var(d):\n",
    "        d = d[topic_name]\n",
    "        d = (d - min(d)) / (max(d) - min(d))\n",
    "        \n",
    "        if np.isnan(np.var(d)):\n",
    "            return 0\n",
    "        \n",
    "        return np.var(d)\n",
    "    \n",
    "    return d.apply(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adaptability_by_focus = calc_unalikeability(gaid, 'donors', 'ad_sector_names')\n",
    "adaptability_by_location =calc_unalikeability(gaid, 'donors', 'NAME_1')\n",
    "adaptability_by_start_year = calc_unalikeability(gaid, 'donors', 'transactions_start_year')\n",
    "adaptability_by_commitment = calc_var(gaid, 'donors', 'total_commitments')\n",
    "\n",
    "#pd.DataFrame.from_dict(adaptability_by_focus, orient = 'index').to_csv('measures_indices\\\\adaptability_by_focus.csv')\n",
    "#pd.DataFrame.from_dict(adaptability_by_location, orient = 'index').to_csv('measures_indices\\\\adaptability_by_location.csv')\n",
    "#pd.DataFrame.from_dict(adaptability_by_start_year, orient = 'index').to_csv('measures_indices\\\\adaptability_by_start_year.csv')\n",
    "#adaptability_by_commitment.to_csv('measures_indices\\\\adaptability_by_commitments.csv')\n",
    "#(adaptability_by_commitment + adaptability_by_start_year + adaptability_by_location + adaptability_by_focus).to_csv('measures_indices\\\\composite_adaptability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_1         Year\n",
       "Bas-Uélé       2014     1\n",
       "Haut-Katanga   2009     1\n",
       "Haut-Uélé      2016     1\n",
       "Ituri          2000     2\n",
       "               2001     6\n",
       "               2004     2\n",
       "               2005     2\n",
       "               2006     3\n",
       "               2008     3\n",
       "               2009     9\n",
       "               2012     1\n",
       "               2013     1\n",
       "               2014     1\n",
       "               2018     4\n",
       "Kasaï          2015     2\n",
       "Kinshasa       2010     1\n",
       "               2015     1\n",
       "Kongo-Central  2001     1\n",
       "Maniema        2002     3\n",
       "               2004     1\n",
       "               2016     3\n",
       "Nord-Kivu      2004     1\n",
       "               2006     3\n",
       "               2008     5\n",
       "               2009     6\n",
       "               2010     5\n",
       "               2011    10\n",
       "               2013    10\n",
       "               2014     7\n",
       "               2015    25\n",
       "               2016    10\n",
       "               2017     2\n",
       "               2018     6\n",
       "Sankuru        1997    10\n",
       "               1998     1\n",
       "               2000     2\n",
       "               2002     1\n",
       "               2003     3\n",
       "               2004     2\n",
       "               2005     5\n",
       "               2006     1\n",
       "Sud-Kivu       2000     1\n",
       "               2001     3\n",
       "               2003     6\n",
       "               2008     1\n",
       "               2009     2\n",
       "               2010     9\n",
       "               2011     7\n",
       "               2016     4\n",
       "               2017     7\n",
       "               2018     1\n",
       "Sud-Ubangi     2016     3\n",
       "Tshopo         2000     1\n",
       "               2003     1\n",
       "Équateur       2016     1\n",
       "Name: Total affected, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_w_d.groupby(['NAME_1', 'Year'])['Total affected'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009    547\n",
       "1996    205\n",
       "1999    160\n",
       "2011    155\n",
       "2013    149\n",
       "2012    147\n",
       "1997    134\n",
       "2002    121\n",
       "2007    117\n",
       "1998    117\n",
       "2014    112\n",
       "2015    111\n",
       "2000    109\n",
       "2008    106\n",
       "2016    103\n",
       "2010     90\n",
       "2006     80\n",
       "2003     67\n",
       "2001     57\n",
       "2004     33\n",
       "2005     25\n",
       "1993     20\n",
       "1995     15\n",
       "1994     14\n",
       "1992     10\n",
       "1991      8\n",
       "1990      4\n",
       "1989      3\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gconflict['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO LIST\n",
    "# 1. Divide donors into 2 groups: higly adaptable and not higly adaptable\n",
    "# 2. Divide areas into two groups: high aid worker casualties and low aid worker casualties. \n",
    "# + consider the time. So, select (year, area) tuples of high/low casualties. \n",
    "\n",
    "# 3. Select projects based on the 4 subcategories derived above.\n",
    "# Projects with: donor is in one of the first classification group.\n",
    "# Start year and area is in one of the second classification groups.\n",
    "\n",
    "#                        High adaptability              Low adaptability\n",
    "#\n",
    "# High receptivity           n                                 n2\n",
    "#\n",
    "# Low receptivity            n3                                n4\n",
    "\n",
    "\n",
    "\n",
    "# 4. THINK ABOUT INFERENCE PROBLEM, MATCHING PROBLEM, CREATING CONTROL AND TREATMENT GROUPS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
